{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "#  torch.cuda.is_available() 함수는 현재 컴퓨터에서 CUDA를 이용할 수 있는 지 알아보는 함수\n",
    "# 오류가 있다면 false 반환\n",
    "# 제대로 설치시 true (CUDA용 파이토치, CUDA도 제대로 설치)\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "# torch.device에 CUDA를 지원하면 \"cuda\"를 \n",
    "# 아니면 \"cpu\"를 설정한 후 변수에 저장 \n",
    "# 나중에 텐서와 가중치에 대한 연산을 CPU와 GPU 중 에서 실행할지 결정할 떄 사용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "# 전체 반복 횟수\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "# FashionMNIST 부터는 데이터가 많아져 한 번에 사용하는 것은 효율적이지 않기 때문에\n",
    "# 여러 개의 미니배치로 잘라서 사용\n",
    "# 각 미니배치의 크기는 64개 \n",
    "\n",
    "transform = transforms.Compose([\n",
    " transforms.ToTensor()\n",
    "])\n",
    "# ToTensor로 이미지를 파이토치 텐서로 변환하고\n",
    "# Compose로 만들어 둔 이미지 변환 설정을 적용하는 데 쓰인다. \n",
    "\n",
    "\n",
    "## FashionMNIST 데이터셋을 가져온다.\n",
    "trainset = datasets.FashionMNIST(\n",
    "    root = './.data/',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = transform\n",
    ")\n",
    "\n",
    "testset = datasets.FashionMNIST(\n",
    "    root = './.data/',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = transform \n",
    ")\n",
    "# download = True로 설정해서 \n",
    "# 자동으로 root 로 지정한 폴더 ( './.data/', ) 에 \n",
    "# 데이터셋이 없다면 자동으로 다운로드 \n",
    "\n",
    "\n",
    "## DataLoader 사용 \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset = trainset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset = testset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이미지 분류를 위한 인공신경망 구현 입력 X와 레이블 Y를 입력 받아 \n",
    "## 학습한 다음 새로운 X가 왔을 때 어떤 패션 아이템인지 예측한다. \n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self): # 선형결합을 수행하는 객체를 만든다. \n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 256) #픽셀값 784개를 입력받아 256 출력 \n",
    "        self.fc2 = nn.Linear(256, 128)#픽셀값 256개를 입력받아 128 출력 \n",
    "        self.fc3 = nn.Linear(128,10) #픽셀값 128개를 입력받아 10 출력\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = x.view(-1,784) #view( ) 로 1차원 행렬을 만든다. \n",
    "        x = F.relu(self.fc1(x)) # fc1()를 거쳐 relu( )활성화 함수 \n",
    "        x = F.relu(self.fc2(x)) # fc2()를 거쳐 relu( )활성화 함수\n",
    "        x = self.fc3(x) # fc3()를 거침 \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(DEVICE) \n",
    "# to 함수로 연산을 어디서 수행할지 결정 \n",
    "# CPU 사용시 to gkatn t0 함수 사용할 필요 x\n",
    "# to(\"cuda\") ->  GPU 사용 \n",
    "# DEVICE 변수를 설정했기 때문에 \n",
    "#자동으로 CUDA를 사용할 경우 GPU로  아닐경우 CPU사용 \n",
    "optimizer = optim.SGD(model.parameters(), lr =0.01) \n",
    "# 최적화 알고리즘으로 파이토치 내장 모듈인 optim.SGD 사용 \n",
    "# 모델 내부의 정보를 넘겨주는 model.parameters() 함수와 \n",
    "# 임의로 설정한 학습률(lr) = 0.01 입력 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 학습에 들어가는 모든 연산 \n",
    "\n",
    "# model- 학습에 필요한 모든 요소 \n",
    "# train_loader - 데이터 공급\n",
    "# optimizer - 최적화 담당 \n",
    "\n",
    "\n",
    "# 모델에 입력하는 data = [배치크기, 색, 높이, 넓이] = [64,1,28,28 ]\n",
    " \n",
    "def train(model, train_loader, optimizer):\n",
    "    model.train() #학습모드로 바꾼다.\n",
    "    \n",
    "    \n",
    "    for batch_idx,(data,target) in enumerate(train_loader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        # 앞서 모델의 가중치를 GPU로 보냈다면 \n",
    "        # 학습 데이터도 같은 장치로 보내야 연산을 수행\n",
    "        optimizer.zero_grad()\n",
    "        # 반복 시마다 기울기를 계산 \n",
    "        output = model(data)\n",
    "        # 학습 데이터에 대한 모델의 예측값을 받아온다. \n",
    "        loss = F.cross_entropy(output,target)\n",
    "        # 앞 장에서는 클래스가 2개 라 이진 교차 엔트로피를 사용하였지만\n",
    "        #이번에는 10개가 존재하기 때문에 교차 엔트로피 사용 \n",
    "        # 앞 장 처럼 criterion() 함수를 만들 수 있으나\n",
    "        # 가중치를 보관할 필요가 없으므로 \n",
    "        # torch.nn.functional 의 cross_entropy() 함수를 직접 사요 ㅇ\n",
    "        loss.backward()\n",
    "        # 기울기 가 계싼 \n",
    "        optimizer.step()\n",
    "        # 계싼한 기울기를 앞 서 정의한 알고리즈메 맞춰 가중치를 수정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    # 평가 모드로 바꾼다. \n",
    "    test_loss = 0 \n",
    "    # 테스트 오차 수 \n",
    "    correct = 0 \n",
    "    # 테스트 예측이 맞은 수 \n",
    "    \n",
    "    with torch.no_grad():# 평가 과정에서는 기울기를 계산하지 않아도 도니다. \n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "            # 학습 때와 같이 데이터를 DEVICE로 내보내고 \n",
    "            # 모델의 예측값(output)를 받아옴\n",
    "            \n",
    "            test_loss += F.cross_entropy(output,target, reduction='sum').item()\n",
    "            # 모든 테스트 오차 더하기\n",
    "            \n",
    "            pred = output.max(1, keepdim = True )[1]\n",
    "            # 가장 큰 값을 가진 클래스가 모델의 예측\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            # 예측과 정답을 비교하여 일치할 경우 correct에 1을 더한다.\n",
    "            # view_as()는 target 텐서를 pred의 모양대로 정렬 \n",
    "            # eq()는 값이 일치하면 1  불일치하면 0\n",
    "            # eq()를 지나고 나면 배치 크기의 배열이 0이나 1로 채워짐\n",
    "            # sum() 함수로 배열 내의 모든 값을 더하면\n",
    "            # 모델이 정답을 맞춘 수를 구할 수 있다. \n",
    "            \n",
    "    test_loss /= len(test_loader.dataset) # 오차 수 / 전체 테스트셋 수\n",
    "    test_accuracy = 100. *correct / len (test_loader.dataset) \n",
    "    #정확도= 정답을 맞춘 수 / 전체 테스트 셋 수  *100\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Test Loss: 0.5873, Accuracy: 79.08%\n",
      "[2] Test Loss: 0.5858, Accuracy: 78.79%\n",
      "[3] Test Loss: 0.5149, Accuracy: 81.51%\n",
      "[4] Test Loss: 0.5078, Accuracy: 81.84%\n",
      "[5] Test Loss: 0.5264, Accuracy: 80.22%\n",
      "[6] Test Loss: 0.4790, Accuracy: 82.85%\n",
      "[7] Test Loss: 0.4885, Accuracy: 82.89%\n",
      "[8] Test Loss: 0.4548, Accuracy: 83.95%\n",
      "[9] Test Loss: 0.4632, Accuracy: 83.26%\n",
      "[10] Test Loss: 0.4418, Accuracy: 84.40%\n",
      "[11] Test Loss: 0.4559, Accuracy: 83.85%\n",
      "[12] Test Loss: 0.4449, Accuracy: 84.08%\n",
      "[13] Test Loss: 0.4301, Accuracy: 84.94%\n",
      "[14] Test Loss: 0.4328, Accuracy: 85.04%\n",
      "[15] Test Loss: 0.4106, Accuracy: 85.47%\n",
      "[16] Test Loss: 0.4327, Accuracy: 84.59%\n",
      "[17] Test Loss: 0.4065, Accuracy: 85.59%\n",
      "[18] Test Loss: 0.4009, Accuracy: 85.69%\n",
      "[19] Test Loss: 0.4178, Accuracy: 84.94%\n",
      "[20] Test Loss: 0.3890, Accuracy: 86.34%\n",
      "[21] Test Loss: 0.3969, Accuracy: 85.81%\n",
      "[22] Test Loss: 0.3949, Accuracy: 85.81%\n",
      "[23] Test Loss: 0.3821, Accuracy: 86.52%\n",
      "[24] Test Loss: 0.4028, Accuracy: 85.50%\n",
      "[25] Test Loss: 0.3811, Accuracy: 86.37%\n",
      "[26] Test Loss: 0.4108, Accuracy: 84.89%\n",
      "[27] Test Loss: 0.3738, Accuracy: 86.72%\n",
      "[28] Test Loss: 0.3830, Accuracy: 86.12%\n",
      "[29] Test Loss: 0.3645, Accuracy: 87.13%\n",
      "[30] Test Loss: 0.3658, Accuracy: 86.98%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # 이폭마다 학습과 테스트셋을 이용하 ㄴ검증을 반복하고 결과를 출력 \n",
    "    train(model, train_loader, optimizer)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    \n",
    "    print('[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "          .format(epoch,test_loss,test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
