{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS =40\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./.data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8db2ab2ace7548a2b2a5d4a87b06b093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./.data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ./.data\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./.data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f581630ee78490f916bb46b6f17b9ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./.data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ./.data\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./.data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a1f7b7ecb03418c80f5c8e0ca9d8a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./.data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ./.data\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./.data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68d58a90d427456fbd81e467d5c864d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./.data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./.data\\FashionMNIST\\raw\n",
      "Processing...\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST(\n",
    "        './.data',\n",
    "        train = True,\n",
    "        download = True,\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,),(0.3081,))\n",
    "        ])\n",
    "    ),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST(\n",
    "        './.data',\n",
    "        train = False,\n",
    "        download = True,\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,),(0.3081,))\n",
    "        ])\n",
    "    ),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.nn.max_pool2d( )\n",
    "\n",
    "    tf.nn.max_pool2d( input, ksize, strides, padding, data_format='NHWC', name=None ) \n",
    "      \n",
    "    - input: Tensor 형식 ( data_format ) .\n",
    "    - ksize: 입력 Tensor의 각 차원에 대한 윈도우 크기 \n",
    "    - strides: 슬라이딩 윈도우의 보폭 \n",
    "    - padding: 'VALID' / 'SAME'\n",
    "    - data_format: 문자열( 'NHWC', 'NCHW'및 'NCHW_VECT_C' 지원 )\n",
    "    - name: 조작 이름 ( option ) \n",
    "    \n",
    "    return Tensor의해 지정된 형식 data_format ( The max pooled output tensor )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# view(*args) \n",
    "    \n",
    "    x = F.relu(F.max_pool2d(self.conv1(x),2)) # 컨볼루션 -> 풀링 \n",
    "    x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)),2)) # 컨볼루션-> 드롭아웃 -> 풀링 \n",
    "    를 통해서 x는 컨볼루션 계층 2개를 거친 특징 맵이 되었다.\n",
    "    x는 이미지 처럼 현재 2차원의 모양새를 하고 있음\n",
    "    특징 맵 이후의 출력을 하는 일반 인공 신경망은 1차원의 입력을 받는다. \n",
    "    2차원 특징 맵을 바로 입력으로 넣을 수 없기 때문에 \n",
    "    view( ) 함수를 통해서 1차원으로 펴준다 ( 차원 축소 )\n",
    "    \n",
    "    view()함수에 들어가는 첫번째 입력 -1은 '남는 차원 모두를 뜻하고, \n",
    "    320은 x가 가진 원소 개수를 의미한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,10,kernel_size = 5)\n",
    "        self.conv2 = nn.Conv2d(10,20,kernel_size = 5)\n",
    "        self.conv2_drop = nn.Dropout2d() #드롭아웃 \n",
    "        self.fc1 = nn.Linear(320,50) # 신경망\n",
    "        self.fc2 = nn.Linear(50,10) # 신경망 \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x),2)) # 컨볼루션 -> 풀링  -> 활성화 함수 \n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)),2)) # 컨볼루션-> 드롭아웃 -> 풀링  -> 활성화 함수 \n",
    "        x = x.view(-1,320) # 차원을 2 에서 1로 \n",
    "        x = F.relu(self.fc1(x)) # 신경망 -> 활성화 함수 \n",
    "        x = F.dropout(x, training = self.training) #드롭아웃 self.training 값은 train 모드인지 아닌지에 따라 t/f\n",
    "        x = self.fc2(x) # 신경망 \n",
    "        return F.log_softmax(x, dim = 1) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  Net().to(DEVICE)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01 , momentum = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train (model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 200 == 0 :\n",
    "            print ('Train Epoch: {} [{}/{} ({:.0f}%)]\\t Loss: {:.6f}'\n",
    "                   .format(epoch, batch_idx*len(data), len(train_loader.dataset),\n",
    "                        100.*batch_idx/len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0 \n",
    "    correct = 0 \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += F.cross_entropy(output, target, reduction = 'sum').item()\n",
    "            \n",
    "            pred = output.max(1, keepdim = True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "    test_loss /=len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len (test_loader.dataset)\n",
    "    \n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\t Loss: 0.853285\n",
      "Train Epoch: 1 [12800/60000 (21%)]\t Loss: 0.776915\n",
      "Train Epoch: 1 [25600/60000 (43%)]\t Loss: 0.824346\n",
      "Train Epoch: 1 [38400/60000 (64%)]\t Loss: 0.702100\n",
      "Train Epoch: 1 [51200/60000 (85%)]\t Loss: 0.646765\n",
      "[1] Test Loss : 0.5500, Accuracy: 78.48%\n",
      "Train Epoch: 2 [0/60000 (0%)]\t Loss: 0.801209\n",
      "Train Epoch: 2 [12800/60000 (21%)]\t Loss: 0.627424\n",
      "Train Epoch: 2 [25600/60000 (43%)]\t Loss: 0.436741\n",
      "Train Epoch: 2 [38400/60000 (64%)]\t Loss: 0.728627\n",
      "Train Epoch: 2 [51200/60000 (85%)]\t Loss: 0.699447\n",
      "[2] Test Loss : 0.5108, Accuracy: 80.05%\n",
      "Train Epoch: 3 [0/60000 (0%)]\t Loss: 0.690432\n",
      "Train Epoch: 3 [12800/60000 (21%)]\t Loss: 0.622497\n",
      "Train Epoch: 3 [25600/60000 (43%)]\t Loss: 0.540587\n",
      "Train Epoch: 3 [38400/60000 (64%)]\t Loss: 0.724310\n",
      "Train Epoch: 3 [51200/60000 (85%)]\t Loss: 0.432773\n",
      "[3] Test Loss : 0.4936, Accuracy: 80.46%\n",
      "Train Epoch: 4 [0/60000 (0%)]\t Loss: 0.606510\n",
      "Train Epoch: 4 [12800/60000 (21%)]\t Loss: 0.675549\n",
      "Train Epoch: 4 [25600/60000 (43%)]\t Loss: 0.647929\n",
      "Train Epoch: 4 [38400/60000 (64%)]\t Loss: 0.756237\n",
      "Train Epoch: 4 [51200/60000 (85%)]\t Loss: 0.582346\n",
      "[4] Test Loss : 0.4683, Accuracy: 82.31%\n",
      "Train Epoch: 5 [0/60000 (0%)]\t Loss: 0.567320\n",
      "Train Epoch: 5 [12800/60000 (21%)]\t Loss: 0.538972\n",
      "Train Epoch: 5 [25600/60000 (43%)]\t Loss: 0.652507\n",
      "Train Epoch: 5 [38400/60000 (64%)]\t Loss: 0.459070\n",
      "Train Epoch: 5 [51200/60000 (85%)]\t Loss: 0.672334\n",
      "[5] Test Loss : 0.4523, Accuracy: 83.45%\n",
      "Train Epoch: 6 [0/60000 (0%)]\t Loss: 0.594247\n",
      "Train Epoch: 6 [12800/60000 (21%)]\t Loss: 0.437168\n",
      "Train Epoch: 6 [25600/60000 (43%)]\t Loss: 0.556596\n",
      "Train Epoch: 6 [38400/60000 (64%)]\t Loss: 0.327373\n",
      "Train Epoch: 6 [51200/60000 (85%)]\t Loss: 0.513994\n",
      "[6] Test Loss : 0.4360, Accuracy: 84.29%\n",
      "Train Epoch: 7 [0/60000 (0%)]\t Loss: 0.361498\n",
      "Train Epoch: 7 [12800/60000 (21%)]\t Loss: 0.408985\n",
      "Train Epoch: 7 [25600/60000 (43%)]\t Loss: 0.503291\n",
      "Train Epoch: 7 [38400/60000 (64%)]\t Loss: 0.511542\n",
      "Train Epoch: 7 [51200/60000 (85%)]\t Loss: 0.497206\n",
      "[7] Test Loss : 0.4187, Accuracy: 84.33%\n",
      "Train Epoch: 8 [0/60000 (0%)]\t Loss: 0.381001\n",
      "Train Epoch: 8 [12800/60000 (21%)]\t Loss: 0.823724\n",
      "Train Epoch: 8 [25600/60000 (43%)]\t Loss: 0.518330\n",
      "Train Epoch: 8 [38400/60000 (64%)]\t Loss: 0.385449\n",
      "Train Epoch: 8 [51200/60000 (85%)]\t Loss: 0.524821\n",
      "[8] Test Loss : 0.4169, Accuracy: 84.78%\n",
      "Train Epoch: 9 [0/60000 (0%)]\t Loss: 0.603551\n",
      "Train Epoch: 9 [12800/60000 (21%)]\t Loss: 0.403256\n",
      "Train Epoch: 9 [25600/60000 (43%)]\t Loss: 0.297092\n",
      "Train Epoch: 9 [38400/60000 (64%)]\t Loss: 0.677961\n",
      "Train Epoch: 9 [51200/60000 (85%)]\t Loss: 0.322867\n",
      "[9] Test Loss : 0.4071, Accuracy: 85.26%\n",
      "Train Epoch: 10 [0/60000 (0%)]\t Loss: 0.579796\n",
      "Train Epoch: 10 [12800/60000 (21%)]\t Loss: 0.552087\n",
      "Train Epoch: 10 [25600/60000 (43%)]\t Loss: 0.536847\n",
      "Train Epoch: 10 [38400/60000 (64%)]\t Loss: 0.360045\n",
      "Train Epoch: 10 [51200/60000 (85%)]\t Loss: 0.450499\n",
      "[10] Test Loss : 0.3883, Accuracy: 86.13%\n",
      "Train Epoch: 11 [0/60000 (0%)]\t Loss: 0.411097\n",
      "Train Epoch: 11 [12800/60000 (21%)]\t Loss: 0.822462\n",
      "Train Epoch: 11 [25600/60000 (43%)]\t Loss: 0.585776\n",
      "Train Epoch: 11 [38400/60000 (64%)]\t Loss: 0.534658\n",
      "Train Epoch: 11 [51200/60000 (85%)]\t Loss: 0.613109\n",
      "[11] Test Loss : 0.3940, Accuracy: 85.74%\n",
      "Train Epoch: 12 [0/60000 (0%)]\t Loss: 0.409545\n",
      "Train Epoch: 12 [12800/60000 (21%)]\t Loss: 0.372827\n",
      "Train Epoch: 12 [25600/60000 (43%)]\t Loss: 0.483828\n",
      "Train Epoch: 12 [38400/60000 (64%)]\t Loss: 0.593020\n",
      "Train Epoch: 12 [51200/60000 (85%)]\t Loss: 0.435403\n",
      "[12] Test Loss : 0.3863, Accuracy: 86.15%\n",
      "Train Epoch: 13 [0/60000 (0%)]\t Loss: 0.450905\n",
      "Train Epoch: 13 [12800/60000 (21%)]\t Loss: 0.605664\n",
      "Train Epoch: 13 [25600/60000 (43%)]\t Loss: 0.497659\n",
      "Train Epoch: 13 [38400/60000 (64%)]\t Loss: 0.479348\n",
      "Train Epoch: 13 [51200/60000 (85%)]\t Loss: 0.635752\n",
      "[13] Test Loss : 0.3745, Accuracy: 86.41%\n",
      "Train Epoch: 14 [0/60000 (0%)]\t Loss: 0.377290\n",
      "Train Epoch: 14 [12800/60000 (21%)]\t Loss: 0.564808\n",
      "Train Epoch: 14 [25600/60000 (43%)]\t Loss: 0.585313\n",
      "Train Epoch: 14 [38400/60000 (64%)]\t Loss: 0.602142\n",
      "Train Epoch: 14 [51200/60000 (85%)]\t Loss: 0.380421\n",
      "[14] Test Loss : 0.3685, Accuracy: 86.58%\n",
      "Train Epoch: 15 [0/60000 (0%)]\t Loss: 0.588947\n",
      "Train Epoch: 15 [12800/60000 (21%)]\t Loss: 0.500403\n",
      "Train Epoch: 15 [25600/60000 (43%)]\t Loss: 0.603505\n",
      "Train Epoch: 15 [38400/60000 (64%)]\t Loss: 0.531354\n",
      "Train Epoch: 15 [51200/60000 (85%)]\t Loss: 0.453784\n",
      "[15] Test Loss : 0.3629, Accuracy: 86.68%\n",
      "Train Epoch: 16 [0/60000 (0%)]\t Loss: 0.288977\n",
      "Train Epoch: 16 [12800/60000 (21%)]\t Loss: 0.534090\n",
      "Train Epoch: 16 [25600/60000 (43%)]\t Loss: 0.577586\n",
      "Train Epoch: 16 [38400/60000 (64%)]\t Loss: 0.460531\n",
      "Train Epoch: 16 [51200/60000 (85%)]\t Loss: 0.366237\n",
      "[16] Test Loss : 0.3618, Accuracy: 86.93%\n",
      "Train Epoch: 17 [0/60000 (0%)]\t Loss: 0.483409\n",
      "Train Epoch: 17 [12800/60000 (21%)]\t Loss: 0.273482\n",
      "Train Epoch: 17 [25600/60000 (43%)]\t Loss: 0.709363\n",
      "Train Epoch: 17 [38400/60000 (64%)]\t Loss: 0.686772\n",
      "Train Epoch: 17 [51200/60000 (85%)]\t Loss: 0.452204\n",
      "[17] Test Loss : 0.3559, Accuracy: 86.73%\n",
      "Train Epoch: 18 [0/60000 (0%)]\t Loss: 0.894098\n",
      "Train Epoch: 18 [12800/60000 (21%)]\t Loss: 0.387715\n",
      "Train Epoch: 18 [25600/60000 (43%)]\t Loss: 0.515512\n",
      "Train Epoch: 18 [38400/60000 (64%)]\t Loss: 0.355955\n",
      "Train Epoch: 18 [51200/60000 (85%)]\t Loss: 0.495248\n",
      "[18] Test Loss : 0.3526, Accuracy: 86.93%\n",
      "Train Epoch: 19 [0/60000 (0%)]\t Loss: 0.442178\n",
      "Train Epoch: 19 [12800/60000 (21%)]\t Loss: 0.343249\n",
      "Train Epoch: 19 [25600/60000 (43%)]\t Loss: 0.719405\n",
      "Train Epoch: 19 [38400/60000 (64%)]\t Loss: 0.211401\n",
      "Train Epoch: 19 [51200/60000 (85%)]\t Loss: 0.374957\n",
      "[19] Test Loss : 0.3467, Accuracy: 87.50%\n",
      "Train Epoch: 20 [0/60000 (0%)]\t Loss: 0.289592\n",
      "Train Epoch: 20 [12800/60000 (21%)]\t Loss: 0.792001\n",
      "Train Epoch: 20 [25600/60000 (43%)]\t Loss: 0.405823\n",
      "Train Epoch: 20 [38400/60000 (64%)]\t Loss: 0.514564\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS+1):\n",
    "    train(model, train_loader, optimizer, epoch)\n",
    "    test_loss, test_accuracy = evaluate( model, test_loader )\n",
    "    \n",
    "    print('[{}] Test Loss : {:.4f}, Accuracy: {:.2f}%'\n",
    "          .format( epoch, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
